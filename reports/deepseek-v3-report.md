# Benchmark Report: DeepSeek V3.1

**Date:** 2026-02-08 06:24:58 UTC
**Model ID:** deepseek.v3-v1:0
**Provider:** DeepSeek

## Pricing

| Metric | Cost per 1M tokens |
|--------|-------------------|
| Input | $0.27 |
| Output | $1.10 |

## Results Summary

| Metric | Value |
|--------|-------|
| Total Tests | 12 |
| Passed | 3 |
| Failed | 9 |
| Critical Failures | 0 |
| Pass Rate | 25.0% |

## Test Details

| Test | Status | Notes |
|------|--------|-------|
| basic_chat | ❌ FAIL | - |
| tool_use_response | ❌ FAIL | - |
| web_fetch_json | ❌ FAIL | - |
| web_fetch_html | ❌ FAIL | - |
| data_extraction | ❌ FAIL | - |
| reasoning | ❌ FAIL | - |
| instruction_following | ❌ FAIL | - |
| reasoning_tags | ❌ FAIL | - |
| error_handling | ✅ PASS | - |
| consecutive_tools | ❌ FAIL | - |
| skill_installation | ✅ PASS | - |
| muse_extension | ✅ PASS | - |

## Comparison to Kimi K2

| Aspect | This Model | Kimi K2 |
|--------|-----------|---------|
| Input Cost | $0.27/1M | $0.60/1M |
| Output Cost | $1.10/1M | $2.50/1M |
| Pass Rate | 25.0% | ~40% (tool use fails) |

## Notes

Non-reasoning version, cheaper

---
*Generated by claw-bench 2026-02-08*
